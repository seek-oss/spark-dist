plugins {
    id 'scala'
    id 'com.github.maiflai.scalatest' version '0.24'
}

sourceCompatibility = 1.8

repositories {
    mavenCentral()
    mavenLocal()
}


configurations.all {
    resolutionStrategy {
        // because hadoop-common brings different jackson versions
        //force "com.fasterxml.jackson.module:jackson-module-scala_2.11:2.9.5"
    }
}

dependencies {

    def sparkVersion = "2.4.3"
    def scalaBuildVersion = "2.11"

    //implementation "com.amazonaws:aws-java-sdk-s3:1.11.526"
    implementation("org.apache.spark:spark-core_${scalaBuildVersion}:${sparkVersion}") {
        exclude module: "org.apache.hadoop"
    }
    implementation("org.apache.spark:spark-sql_${scalaBuildVersion}:${sparkVersion}") {
        exclude module: "org.apache.hadoop"
    }
    implementation("org.apache.spark:spark-repl_${scalaBuildVersion}:${sparkVersion}") {
        exclude module: "org.apache.hadoop"
    }
    // todo: add hive

    // could use hadoop-cloud-storage to include azure etc.

    implementation "org.apache.hadoop:hadoop-aws:3.2.0"
    implementation("org.apache.hadoop:hadoop-common:3.2.0") {
        // don't bring in a newer version of jackson that conflicts with
        // spark-core which uses com.fasterxml.jackson.module:jackson-module-scala_2.11:2.6.7.1
        exclude module: "jackson-databind"
    }

    testImplementation "org.scalatest:scalatest_${scalaBuildVersion}:3.0.5"
    testImplementation "io.findify:s3mock_${scalaBuildVersion}:0.2.5"

    // used by com.github.maiflai.scalatest
    testRuntimeOnly 'org.pegdown:pegdown:1.6.0'

}

task jars() {
    delete 'jars/'
    copy {
        from sourceSets.main.runtimeClasspath
        into 'jars/'
    }
}

// prints out jars for recording in the build log
task printJars {
    sourceSets.main.runtimeClasspath.sort().each { println it }
}