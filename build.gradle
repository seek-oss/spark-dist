plugins {
    id 'scala'
    id 'com.github.maiflai.scalatest' version '0.24'
}

sourceCompatibility = 1.8

repositories {
    mavenCentral()
    mavenLocal()
}


dependencies {

    def sparkVersion = "2.4.3"
    def scalaBuildVersion = "2.11"

    implementation("org.apache.spark:spark-repl_${scalaBuildVersion}:${sparkVersion}")

    constraints {
        implementation("org.apache.hadoop:hadoop-client:3.2.0") {
            because "override 2.6.5 requested by spark-core to match hadoop-aws"
        }
        implementation("com.fasterxml.jackson.module:jackson-module-scala_${scalaBuildVersion}:2.9.5") {
            because "override 2.6.7.1 requested by spark-core to match hadoop jars"
        }
    }
    // todo: add hive

    // could use hadoop-cloud-storage to include azure etc.
    implementation "org.apache.hadoop:hadoop-aws:3.2.0"

    testImplementation "org.scalatest:scalatest_${scalaBuildVersion}:3.0.5"
    testImplementation "io.findify:s3mock_${scalaBuildVersion}:0.2.5"

    // used by com.github.maiflai.scalatest
    testRuntimeOnly 'org.pegdown:pegdown:1.6.0'

}

task jars() {
    delete 'jars/'
    copy {
        from sourceSets.main.runtimeClasspath
        into 'jars/'
    }
}

// prints out jars for recording in the build log
task printJars {
    sourceSets.main.runtimeClasspath.sort().each { println it }
}