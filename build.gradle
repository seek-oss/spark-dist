plugins {
    id 'scala'
    id 'com.github.maiflai.scalatest' version '0.29'
}

sourceCompatibility = 1.8

repositories {
    mavenCentral()
    mavenLocal()
}


dependencies {

    def sparkVersion = "2.4.3"
    def scalaBuildVersion = "2.11"
    def hadoopVersion = "3.1.3"

    implementation("org.apache.spark:spark-repl_${scalaBuildVersion}:${sparkVersion}")

    // exclude hive because it doesn't work with hadoop 3 see HIVE-15326
    // work to fix this for spark is tracked in SPARK-23710

    // implementation("org.apache.spark:spark-hive_${scalaBuildVersion}:${sparkVersion}")

    constraints {
        implementation("org.apache.hadoop:hadoop-client:${hadoopVersion}") {
            because "override 2.6.5 requested by spark-core to match hadoop-aws"
        }
        implementation("com.fasterxml.jackson.module:jackson-module-scala_${scalaBuildVersion}:2.12.0") {
            because "override 2.6.7.1 requested by spark-core to match hadoop jars"
        }
    }

    // could use hadoop-cloud-storage to include azure etc.
    implementation "org.apache.hadoop:hadoop-aws:${hadoopVersion}"

    testImplementation "org.scalatest:scalatest_${scalaBuildVersion}:3.0.5"
    testImplementation "io.findify:s3mock_${scalaBuildVersion}:0.2.6"

    // used by com.github.maiflai.scalatest
    testRuntimeOnly 'org.pegdown:pegdown:1.6.0'

}

task jars() {
    doLast {
        delete 'jars/'
        copy {
            from sourceSets.main.runtimeClasspath
            into 'jars/'
        }
    }
}

// prints out jars for recording in the build log
task printJars {
    doLast {
        sourceSets.main.runtimeClasspath.sort().each { println it }
    }
}